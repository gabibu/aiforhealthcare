{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline model UNET\n",
    "# I splitted every image to patches of 64 * 64 pixels \n",
    "#and classified every pixel in every patch as binary classification  task\n",
    "\n",
    "\n",
    "#so for the model the input is 64 * 64 pixels images.\n",
    "\n",
    "\n",
    "#model: UNET\n",
    "#loss Binary cross entropy \n",
    "#optimizer: SGD\n",
    "\n",
    "#I splitted to dataset under to dicom-images-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from mask_functions import rle2mask\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__pyTorch VERSION: 1.10.1+cu102\n",
      "use_cuda = True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('use_cuda = {0}'.format(use_cuda))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DATA_FOLDER ='data'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SEED = 999\n",
    "\n",
    "def fixSeed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "fixSeed(SEED)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('archive/train-rle.csv', header=None, index_col=0)\n",
    "train_fns = sorted(glob.glob('archive/dicom-images-train/*/*/*.dcm'))[0:500]\n",
    "df_full = pd.read_csv('archive/train-rle.csv', index_col='ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 273/500 [00:02<00:01, 139.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 1.2.276.0.7230010.3.1.4.8323329.10231.1517875222.737143 without mask, assuming healthy patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 424/500 [00:03<00:00, 144.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 1.2.276.0.7230010.3.1.4.8323329.10362.1517875223.377845 without mask, assuming healthy patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 470/500 [00:03<00:00, 142.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 1.2.276.0.7230010.3.1.4.8323329.10407.1517875223.567351 without mask, assuming healthy patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 137.41it/s]\n"
     ]
    }
   ],
   "source": [
    "im_height = 1024\n",
    "im_width = 1024\n",
    "im_chan = 1\n",
    "X_s = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_s = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.bool)\n",
    "sys.stdout.flush()\n",
    "for n, _id in tqdm(enumerate(train_fns), total=len(train_fns)):\n",
    "    dataset = pydicom.read_file(_id)\n",
    "    X_s[n] = np.expand_dims(dataset.pixel_array, axis=2)\n",
    "    try:\n",
    "        if '-1' in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n",
    "            Y_s[n] = np.zeros((1024, 1024, 1))\n",
    "        else:\n",
    "            if type(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']) == str:\n",
    "                Y_s[n] = np.expand_dims(rle2mask(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n",
    "            else:\n",
    "                Y_s[n] = np.zeros((1024, 1024, 1))\n",
    "                for x in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n",
    "                    Y_s[n] =  Y_s[n] + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n",
    "    except KeyError:\n",
    "        print(f\"Key {_id.split('/')[-1][:-4]} without mask, assuming healthy patient.\")\n",
    "        Y_s[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 1024, 1024, 1), (500, 1024, 1024, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_s.shape, Y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 1024, 1024, 1), (450, 1024, 1024, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_size = int(Y_s.shape[0] * 0.1)\n",
    "validation_indexes = np.random.choice(range(0, Y_s.shape[0]), size=validation_size, replace=False)\n",
    "train_indexes  = [i for i in range(0, Y_s.shape[0]) if i not in validation_indexes]\n",
    "\n",
    "\n",
    "y_train = Y_s[train_indexes, :, :]\n",
    "y_validation = Y_s[validation_indexes, :, :]\n",
    "\n",
    "\n",
    "\n",
    "X_validation = X_s[validation_indexes, :, :]\n",
    "X_train = X_s[train_indexes, :, :]\n",
    "\n",
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115200, 64, 64, 1), (115200, 64, 64, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_height = 64\n",
    "im_width = 64\n",
    "X_train = X_train.reshape((-1, im_height, im_width, 1))\n",
    "y_train = y_train.reshape((-1, im_height, im_width, 1))\n",
    "\n",
    "\n",
    "X_validation = X_validation.reshape((-1, im_height, im_width, 1))\n",
    "y_validation = y_validation.reshape((-1, im_height, im_width, 1))\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.masks.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        y = self.masks[index]\n",
    "        y = np.where(y == True, 1, 0)\n",
    "        \n",
    "        image  = X_train[index]\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "        y = y.reshape(1, y.shape[0], y.shape[1])\n",
    "        \n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(X_train, y_train)\n",
    "validation_generator = DataGenerator(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115200, 64, 64, 1), (115200, 64, 64, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, confusion_matrix, optimizer, criterion, input_transformation=None):\n",
    "    calc_loss = 0.\n",
    "    calc_count = 0.\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in data_loader:\n",
    "\n",
    "        calc_count += labels.shape[0]\n",
    "        images = images.float().to(device)\n",
    "     \n",
    "        labels = labels.float().to(device)\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        calc_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return calc_loss/calc_count\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    calc_loss = 0.\n",
    "    calc_count = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            calc_count += labels.shape[0]\n",
    "            images = images.float().to(device)\n",
    "\n",
    "            labels = labels.float().to(device)\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            calc_loss += loss.item()\n",
    "            \n",
    "        \n",
    "    return calc_loss/calc_count\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(1, 1, False).to(device)\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "momentum = 0.9\n",
    "number_of_epoch = 100 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "data_loader = DataLoader(training_generator, batch_size=8, shuffle=True, num_workers=0)\n",
    "validation_data_loader = DataLoader(validation_generator, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(epoch)\n",
    "    train_loss = train(model, data_loader, None, optimizer, criterion, None)\n",
    "    val_loss = eval_model(model, validation_data_loader, criterion)\n",
    "    \n",
    "    print('epoch {} train loss {} val loss {}'.format(epoch, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS1(1)",
   "language": "python",
   "name": "rs1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
