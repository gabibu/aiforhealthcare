{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_models_colab_2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPiTGSOuSMNQcF7O63WF6P3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabibu/aiforhealthcare/blob/main/advanced_models_colab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLpNDt_Q8omW",
        "outputId": "a71e4a01-74b9-43e3-ac9a-6e15ff576702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, WeightedRandomSampler\n",
        "from skimage import io, transform\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "from torchvision import transforms, datasets\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from imageio import imread\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import cm\n",
        "\n",
        "import pydicom\n",
        "from abc import ABC, abstractmethod\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomVerticalFlip, RandomRotation\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "o5WW9fOG8yGv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask2rle(img, width, height):\n",
        "    rle = []\n",
        "    lastColor = 0;\n",
        "    currentPixel = 0;\n",
        "    runStart = -1;\n",
        "    runLength = 0;\n",
        "\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            currentColor = img[x][y]\n",
        "            if currentColor != lastColor:\n",
        "                if currentColor == 255:\n",
        "                    runStart = currentPixel;\n",
        "                    runLength = 1;\n",
        "                else:\n",
        "                    rle.append(str(runStart));\n",
        "                    rle.append(str(runLength));\n",
        "                    runStart = -1;\n",
        "                    runLength = 0;\n",
        "                    currentPixel = 0;\n",
        "            elif runStart > -1:\n",
        "                runLength += 1\n",
        "            lastColor = currentColor;\n",
        "            currentPixel+=1;\n",
        "\n",
        "    return \" \".join(rle)\n",
        "\n",
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width* height)\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        current_position += start\n",
        "        mask[current_position:current_position+lengths[index]] = 255\n",
        "        current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height)\n"
      ],
      "metadata": {
        "id": "qpIf5f4r80BT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('__pyTorch VERSION:', torch.__version__)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('use_cuda = {0}'.format(use_cuda))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "DATA_FOLDER ='data'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "wXonbcyb81zy",
        "outputId": "cac5015c-a907-4a46-8a78-77cc6633bb23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__pyTorch VERSION: 1.11.0+cu113\n",
            "use_cuda = True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SGNjIDb84Ki",
        "outputId": "9d9ac3cf-86b0-465b-81d3-1d01ac039bc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/medical\"\n"
      ],
      "metadata": {
        "id": "JIY1qbER_a8g",
        "outputId": "6632a619-6f68-496f-ce21-46150a591f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aug.weights\t\tsimple_preprocessing.weights  weighted_2.weights\n",
            "dicom-images-train.zip\ttrain-rle.csv\t\t      weighted_sampling.weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/medical/dicom-images-train.zip\" \"dicom-images-train.zip\"\n"
      ],
      "metadata": {
        "id": "EHkymXwS_dUM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/My Drive/medical/train-rle.csv' \"train-rle.csv\"\n"
      ],
      "metadata": {
        "id": "QWSV58ND_fav"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "oAV8JeNI_hOe",
        "outputId": "67aee309-9742-43e6-f641-ebe102d895ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dicom-images-train.zip\tdrive  sample_data  train-rle.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  -q dicom-images-train.zip -d data \n"
      ],
      "metadata": {
        "id": "rRm5Sb7S_jxF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 999\n",
        "\n",
        "def fixSeed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if use_cuda:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "fixSeed(SEED)\n",
        "SEED"
      ],
      "metadata": {
        "id": "eV6fF_SE_nNG",
        "outputId": "a6c28bde-2a7f-4104-80b1-a72cc00a9c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('train-rle.csv', header=None, index_col=0)\n",
        "# train_fns = sorted(glob.glob('data/dicom-images-train/*/*/*.dcm'))\n",
        "# len(train_fns)\n",
        "# df_full = pd.read_csv('train-rle.csv', index_col='ImageId')\n",
        "# df_full.sample(1)"
      ],
      "metadata": {
        "id": "a2D252K7_ph9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "id": "tGwpHi5a_xi9",
        "outputId": "1e1c2229-fd91-4a22-d3a1-95c7ab33f0ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dicom-images-train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs_paths = sorted(glob.glob('data/dicom-images-train/*/*/*.dcm'))\n",
        "print(\"Train images size {}\".format(len(train_imgs_paths)))\n",
        "\n",
        "# test_imgs_paths = sorted(glob('../input/siim-acr-pneumothorax-segmentation-data/dicom-images-test/*/*/*.dcm'))\n",
        "# print(\"Test images -\", len(test_imgs_paths))\n",
        "# file_paths = train_imgs_paths + test_imgs_paths"
      ],
      "metadata": {
        "id": "N8f4zLyU_wo9",
        "outputId": "1a93f354-bd20-45b0-ba8f-7dfd09fb9035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images size 10712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_df = pd.read_csv('train-rle.csv')\n",
        "# data_df.rename(columns={\" EncodedPixels\" : \"EncodedPixels\"}, inplace=True) # a typo in the csv\n",
        "# data_df.head()\n",
        "\n",
        "rles_df = pd.read_csv('train-rle.csv')\n",
        "rles_df = rles_df.rename(columns={' EncodedPixels':'EncodedPixels'})\n",
        "rles_df['EncodedPixels'] = rles_df['EncodedPixels'].apply(lambda x: x.strip())\n",
        "\n",
        "# Create a dictionary for images with masks\n",
        "rles_df = rles_df[rles_df['EncodedPixels'] !='-1'].groupby('ImageId')['EncodedPixels'].apply(list).reset_index()\n",
        "print(len(rles_df))\n",
        "\n",
        "masks = {}\n",
        "for index, row in rles_df.iterrows():\n",
        "    masks[row['ImageId']] = row['EncodedPixels']\n",
        "print(len(masks))"
      ],
      "metadata": {
        "id": "Lv2wHMTfAONf",
        "outputId": "c36eddae-640d-4e29-d47b-2f6380d655a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2379\n",
            "2379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_split(train_imgs_paths, test_size = 0.1)\n",
        "\n",
        "X_train, X_val = train_test_split(train_imgs_paths, test_size=0.1, random_state=SEED)\n",
        "len(X_train), len(X_val)"
      ],
      "metadata": {
        "id": "k8E6UdqpBD3X",
        "outputId": "de06630d-3044-4a29-90ca-b8c7da6ab4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9640, 1072)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}